project assignment - ETL of hospital data
created by - saurabh rathor
date - 23-05-2021
---------------------------------------------------------------------------------------------------------------------------------------------------------------------

step by step program expalined -

(1) importing necessory libraries
   from pyspark.sql import SparkSession
   from pyspark.sql.functions import *
   from pyspark.sql.types import *
   import os
  
  
(2) creating entrypoint 
   spark = SparkSession.builder.enableHiveSupport().appName('ETl job').getOrCreate()
   spark.sql('set spark.sql.sources.partitionOverwriteMode=dynamic')

(3) reading a csv file from local and spitting into pip delimiter 
    reading = spark.read.csv('sample.csv', sep="|", header="True")
   
(4) now removing some colummns whiich is not required
    df = reading.drop('_c0', 'H')
    
(5) casting schema into StringType , IntegerType , DateType
    df2 = df.withColumn('Customer_Name', col('Customer_Name').cast(StringType())) \
    .withColumn('Customer_Id', col('Customer_Id').cast(StringType())) \
    .withColumn('Open_Date', to_date(col('Open_Date'), "yyyymmdd").cast(DateType())) \
    .withColumn('Last_Consulted_Date', to_date(col('Last_Consulted_Date'), "yyyymmdd").cast(DateType())) \
    .withColumn('Vaccination_Id', col('Vaccination_Id').cast(StringType())) \
    .withColumn('Dr_Name', col('Dr_Name').cast(StringType())) \
    .withColumn('State', col('State').cast(StringType())) \
    .withColumn('Country', col('Country').cast(StringType())) \
    .withColumn('DOB', to_date(col('DOB'), "ddmmyyyy").cast(DateType())) \
    .withColumn('Is_Active', col('Is_Active').cast(StringType()))
    
    
(6) taking input from user -new table wiil be created or previous table overwite 

    name = input("enter your table name :----->")
    
(7) handling execptation for name input is correct then file will save as country based csv format
    and if name is not given by user then file will be saved in defalut table
    try:

    if not name:
        name = 'default_table'
        df2.write.option("header", "true"). \
            saveAsTable(name=name, format='csv', mode='overwrite', partitionBy='Country')
     except:
    print("table not found")      
            
(8) # showing currunet path of file saved
    cwd = os.getcwd() + '/spark-warehouse/' + name + '/'
    print("file has been saved in ", cwd)
    
(9) printing data for user to select country and country will be uniq
    country_options = df2.select('Country').distinct().show()

(10) taking country input from user and also printing output
try:
    which_country = input('which country data do you want ----->')
    reading_data = spark.read.csv(path='file:' + cwd + 'Country=' + which_country.upper(),
                                  sep=",", header="True", inferSchema='True')
    reading_data.printSchema()
    reading_data.show()

except:
    print('plz enter correct country or path not found')








